# ğŸ“ utils.py (ë³´í—˜ì‚¬ ì¶”ì²œ ê°œì„  + ì¶”ì²œ í•„í„° ì»¬ëŸ¼ ìë™ ìƒì„± + ëˆ„ì  ê¸°ë¡ ê¸°ëŠ¥)

import pandas as pd
import json
import os
import csv
from datetime import datetime

# âœ… ìœ„í—˜ë“±ê¸‰ ì ìˆ˜ ë§µ (ê²Œì´ì§€ ì°¨íŠ¸ìš©)
risk_score_map = {
    "ë§¤ìš° ë‚®ìŒ": 10,
    "ë‚®ìŒ": 25,
    "ë³´í†µ": 50,
    "ë†’ìŒ": 75,
    "ë§¤ìš° ë†’ìŒ": 90
}

def load_data_sources_safe():
    """
    ì•”ì¢…, ì†Œë“, ë³‘ì›ìœ í˜•, ë³´í—˜ì‚¬ ë°ì´í„° ë¡œë“œ
    (ì˜ˆì™¸ì²˜ë¦¬ í¬í•¨ + ì¶”ì²œì •ë³´ ì»¬ëŸ¼ ìë™ ì¶”ê°€)
    """
    try:
        # âœ… ìƒëŒ€ ê²½ë¡œë¡œ ë¡œë“œ
        df_t1 = pd.read_excel("data/t1.xlsx")
        df_t2 = pd.read_excel("data/t2.xlsx")
        df_t3 = pd.read_excel("data/t3.xlsx")

        with open("data/life_insurance_general.json", "r", encoding="utf-8") as f:
            raw_json = json.load(f)

        items = raw_json["response"]["body"]["tableList"][0]["items"]["item"]
        insurance_df = pd.DataFrame(items)

        # âœ… ì»¬ëŸ¼ëª… ì •ë¦¬ ë° í•„í„°ë§
        insurance_df = insurance_df.rename(columns={
            "fncoNm": "ë³´í—˜ì‚¬ëª…",
            "xcsmPlnpnCnt": "ì¸ì›ìˆ˜",
            "xcsmPlnpnDcdNm": "êµ¬ë¶„"
        })
        insurance_df = insurance_df[insurance_df["ë³´í—˜ì‚¬ëª…"].str.contains("ë³´í—˜", na=False)].copy()
        insurance_df["ì¸ì›ìˆ˜"] = pd.to_numeric(insurance_df["ì¸ì›ìˆ˜"], errors="coerce").fillna(0)

        # âœ… ë³´í—˜ì‚¬ ê·œëª¨ ë¶„ë¥˜
        def assign_scale(count):
            if count >= 3000:
                return "ëŒ€í˜•"
            elif count >= 1000:
                return "ì¤‘í˜•"
            else:
                return "ì†Œí˜•"

        insurance_df["ë³´í—˜ì‚¬ê·œëª¨"] = insurance_df["ì¸ì›ìˆ˜"].apply(assign_scale)
        insurance_df = insurance_df.drop_duplicates(subset=["ë³´í—˜ì‚¬ëª…"])

        # âœ… ì¶”ì²œ ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if "ë³´ì¥ìœ í˜•" not in insurance_df.columns:
            insurance_df["ë³´ì¥ìœ í˜•"] = "ì•” ì „ìš©"
        if "í‰ê· ë³´í—˜ë£Œ" not in insurance_df.columns:
            insurance_df["í‰ê· ë³´í—˜ë£Œ"] = "ì¤‘ê°„"
        if "ëª¨ë°”ì¼ê°€ì…" not in insurance_df.columns:
            insurance_df["ëª¨ë°”ì¼ê°€ì…"] = True
        if "ë¯¼ì›ë¥ " not in insurance_df.columns:
            insurance_df["ë¯¼ì›ë¥ "] = 1.2  # ê¸°ë³¸ í‰ê·  ë¯¼ì›ë¥ 

        return df_t1, df_t2, df_t3, insurance_df

    except Exception as e:
        raise RuntimeError(f"[load_data_sources ì˜¤ë¥˜] {e}")


def recommend_insurance_company(risk_level: str, df: pd.DataFrame) -> pd.DataFrame:
    """
    ìœ„í—˜ë“±ê¸‰ì— ë”°ë¼ ë³´í—˜ì‚¬ ì¶”ì²œ ëª©ë¡ ë°˜í™˜ (ì •ë ¬ ê¸°ì¤€ í¬í•¨)
    """
    if "ë³´í—˜ì‚¬ê·œëª¨" not in df.columns:
        raise KeyError("âŒ ë³´í—˜ì‚¬ê·œëª¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ ì»¬ëŸ¼: " + ", ".join(df.columns))

    if risk_level in ["ë§¤ìš° ë‚®ìŒ", "ë‚®ìŒ"]:
        filtered = df[df["ë³´í—˜ì‚¬ê·œëª¨"].isin(["ì†Œí˜•", "ì¤‘í˜•"])].copy()
    elif risk_level in ["ë³´í†µ", "ë†’ìŒ"]:
        filtered = df[df["ë³´í—˜ì‚¬ê·œëª¨"].isin(["ì¤‘í˜•", "ëŒ€í˜•"])].copy()
    elif risk_level == "ë§¤ìš° ë†’ìŒ":
        filtered = df[df["ë³´í—˜ì‚¬ê·œëª¨"] == "ëŒ€í˜•"].copy()
    else:
        raise ValueError(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ìœ„í—˜ë“±ê¸‰: '{risk_level}'")

    # âœ… ìš°ì„ ìˆœìœ„ ì •ë ¬: ëª¨ë°”ì¼ê°€ì… â†’ ë³´í—˜ì‚¬ê·œëª¨ â†’ ì¸ì›ìˆ˜
    filtered = filtered.sort_values(
        by=["ëª¨ë°”ì¼ê°€ì…", "ë³´í—˜ì‚¬ê·œëª¨", "ì¸ì›ìˆ˜"],
        ascending=[False, False, False]
    )

    return filtered.reset_index(drop=True)


def log_risk_score(region: str, age_group: str, risk_score: int, path: str = "data/risk_history.csv"):
    """
    ì§€ì—­ + ì—°ë ¹ëŒ€ ê¸°ë°˜ ìœ„í—˜ë„ ê¸°ë¡ (ëˆ„ì  ì €ì¥)
    """
    if "/" in path:
        os.makedirs(os.path.dirname(path), exist_ok=True)

    write_header = not os.path.exists(path)
    with open(path, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if write_header:
            writer.writerow(["timestamp", "region", "age_group", "risk_score"])
        writer.writerow([datetime.now().isoformat(), region, age_group, risk_score])